# using-agi-without-losing-human-agency
A PKF-based non-intervention framework for using AGI in human relationships while preserving human agency.
## Overview

This repository presents a non-intervention framework for using
Artificial General Intelligence (AGI) in human relationships
without displacing human agency.

The framework is grounded in the Pain Kernel Framework (PKF) and
defines strict boundaries for how AGI-generated analyses
(e.g., compatibility analysis, success probability estimation,
cost–benefit evaluation) may be used in relational contexts.

This work does NOT provide advice, predictions, recommendations,
or prescriptions.
It specifies structural limits intended to preserve
human responsibility, interruption, and meaning delay.

---

## Core Principles

- **Non-Intervention**  
  AGI must not prescribe actions or recommend relational decisions.

- **Interruption Before Decision**  
  AGI outputs must not collapse directly into human action.
  A decisional pause is a required human function.

- **Responsibility Retention**  
  Responsibility for relational choices must remain exclusively human.
  “The AI said so” is treated as an invalid justification.

- **Meaning Delay**  
  AGI must not assign success, failure, or value to relationships.

---

## What AGI Is Allowed to Do (Limited Scope)

- Expose recurring relational patterns
- Highlight potential structural costs
- Interrupt cognitive bias
- Surface historical similarities without conclusions

---

## What AGI Is Explicitly Restricted From Doing

- Assigning meaning to relationships
- Recommending actions (e.g., stay, leave, commit)
- Optimizing relational outcomes
- Acting as a decision authority

---

## Academic Context

This repository accompanies the academic paper:

**Using AGI in Human Relationships Without Losing Human Agency**  
A PKF-Based Non-Intervention Model

The canonical academic version is archived with a DOI
to ensure citability and long-term preservation.

---

## Intended Audience

- AGI Safety researchers
- Human-Centered AI designers
- AI ethics scholars
- System architects working on relational AI tools

---

## Disclaimer

This framework is descriptive and normative.
It does not claim to improve decision accuracy or outcomes.
Its sole purpose is to preserve human agency
in the presence of increasingly capable AI systems.

---

## License

CC BY 4.0 (Creative Commons Attribution 4.0)
